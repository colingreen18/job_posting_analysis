{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file updates the csv file with current job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "searches = ['data intern', 'data analyst', 'data scientist', 'machine learning', 'data student', 'junior analyst', 'python analyst']\n",
    "range = 3\n",
    "radius = 100\n",
    "location = 'vancouver'\n",
    "province = 'BC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_urls(location, province, searches, radius=100, range=14):\n",
    "    \"\"\"create a list of urls for multiple searches\"\"\"\n",
    "    print('creating urls')\n",
    "    urls_list = []\n",
    "    for search in searches:\n",
    "        search = search.split(\" \")\n",
    "        search = '+'.join(search)\n",
    "        url = 'https://ca.indeed.com/jobs?q=' + search\n",
    "        url = url + '&l=' + location + '%2C+' + province\n",
    "        url = url + '&radius=' + str(radius) + '&sort=date'\n",
    "        url = url + '&fromage=' + str(range) + '&filter=0'\n",
    "        for i in [0, 10, 20, 30]:\n",
    "            url = url + '&start=' + str(i)\n",
    "            urls_list.append(url)\n",
    "    return urls_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating urls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://ca.indeed.com/jobs?q=data+intern&l=vancouver%2C+BC&radius=100&sort=date&fromage=3&filter=0&start=0'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = create_urls(location, province, searches, range=range, radius=radius)\n",
    "urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages(urls):\n",
    "    \"\"\"get the page data for each search\"\"\"\n",
    "    print('getting pages')\n",
    "    pages = []\n",
    "    for url in urls:\n",
    "        pages.append(requests.get(url))\n",
    "        time.sleep(10)\n",
    "        if len(pages) % 5 == 0:\n",
    "            print(f'{len(pages)} pages found')\n",
    "    soups = [BeautifulSoup(page.text, 'html.parser') for page in pages]\n",
    "    return soups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting pages\n",
      "5 pages found\n",
      "10 pages found\n",
      "15 pages found\n",
      "20 pages found\n",
      "25 pages found\n"
     ]
    }
   ],
   "source": [
    "soups = get_pages(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_title_from_result(soups):\n",
    "    print('getting job titles')\n",
    "    jobs = []\n",
    "    for soup in soups:\n",
    "        for div in soup.find_all(name='div', attrs={'class': 'row'}):\n",
    "            for a in div.find_all(name='a', attrs={'data-tn-element': 'jobTitle'}):\n",
    "                jobs.append(a['title'])\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting job titles\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Business Analyst Co-op Student - Richmond, B.C. - R09857'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles = extract_job_title_from_result(soups)\n",
    "job_titles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company_from_result(soups):\n",
    "    print('getting company names')\n",
    "    companies = []\n",
    "    for soup in soups:\n",
    "        for div in soup.find_all(name='div', attrs={'class': 'row'}):\n",
    "            company = div.find_all(name='span', attrs={'class': 'company'})\n",
    "            if len(company) > 0:\n",
    "                for b in company:\n",
    "                    companies.append(b.text.strip())\n",
    "                else:\n",
    "                    sec_try = div.find_all(name='span', attrs={'class': 'result-link-source'})\n",
    "                    for span in sec_try:\n",
    "                        companies.append(span.text.strip())\n",
    "    return(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting company names\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'MDA'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies = extract_company_from_result(soups)\n",
    "companies[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location_from_result(soups):\n",
    "    print('getting locations')\n",
    "    locations = []\n",
    "    for soup in soups:\n",
    "        spans = soup.findAll('span', attrs={'class': 'location'})\n",
    "        for span in spans:\n",
    "            locations.append(span.text)\n",
    "    return(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting locations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Richmond, BC'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations = extract_location_from_result(soups)\n",
    "locations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>href</th>\n",
       "      <th>description</th>\n",
       "      <th>apply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst Co-op (Spring term)</td>\n",
       "      <td>Ridley College (Canada)</td>\n",
       "      <td>St. Catharines, ON</td>\n",
       "      <td>https://ca.indeed.com/rc/clk?jk=4aafa08c370b87...</td>\n",
       "      <td>[[&lt;div&gt;&lt;p&gt;&lt;b&gt;Position Title: Data Analyst Co-o...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analytics Associate Summer Intern (MBA)</td>\n",
       "      <td>Johnson &amp; Johnson Family of Companies</td>\n",
       "      <td>Toronto, ON</td>\n",
       "      <td>https://ca.indeed.com/rc/clk?jk=1d1d136f3b5263...</td>\n",
       "      <td>[[&lt;div&gt;&lt;p&gt;&lt;b&gt;Data Analytics Associate Intern â€“...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst, Summer 2021 Student Opportunities</td>\n",
       "      <td>RBC</td>\n",
       "      <td>Toronto, ON</td>\n",
       "      <td>https://ca.indeed.com/rc/clk?jk=5bc75ed7e05b22...</td>\n",
       "      <td>[[&lt;div&gt;&lt;p&gt;&lt;b&gt;What is the opportunity?&lt;/b&gt;&lt;br/&gt;...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist, Summer Student 2021 Opportunities</td>\n",
       "      <td>RBC</td>\n",
       "      <td>Toronto, ON</td>\n",
       "      <td>https://ca.indeed.com/rc/clk?jk=1bdf42b3d5b3e4...</td>\n",
       "      <td>[[&lt;div&gt;&lt;p&gt;&lt;b&gt;What is the opportunity?&lt;/b&gt;&lt;br/&gt;...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business/Operations Analyst, Summer 2021 Stude...</td>\n",
       "      <td>RBC</td>\n",
       "      <td>Toronto, ON</td>\n",
       "      <td>https://ca.indeed.com/rc/clk?jk=76d9a17c168e02...</td>\n",
       "      <td>[[&lt;div&gt;&lt;p&gt;&lt;b&gt;What is the opportunity?&lt;/b&gt;&lt;/p&gt;&lt;...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0                   Data Analyst Co-op (Spring term)   \n",
       "1       Data Analytics Associate Summer Intern (MBA)   \n",
       "2    Data Analyst, Summer 2021 Student Opportunities   \n",
       "3  Data Scientist, Summer Student 2021 Opportunities   \n",
       "4  Business/Operations Analyst, Summer 2021 Stude...   \n",
       "\n",
       "                                 company            location  \\\n",
       "0                Ridley College (Canada)  St. Catharines, ON   \n",
       "1  Johnson & Johnson Family of Companies         Toronto, ON   \n",
       "2                                    RBC         Toronto, ON   \n",
       "3                                    RBC         Toronto, ON   \n",
       "4                                    RBC         Toronto, ON   \n",
       "\n",
       "                                                href  \\\n",
       "0  https://ca.indeed.com/rc/clk?jk=4aafa08c370b87...   \n",
       "1  https://ca.indeed.com/rc/clk?jk=1d1d136f3b5263...   \n",
       "2  https://ca.indeed.com/rc/clk?jk=5bc75ed7e05b22...   \n",
       "3  https://ca.indeed.com/rc/clk?jk=1bdf42b3d5b3e4...   \n",
       "4  https://ca.indeed.com/rc/clk?jk=76d9a17c168e02...   \n",
       "\n",
       "                                         description apply  \n",
       "0  [[<div><p><b>Position Title: Data Analyst Co-o...   Yes  \n",
       "1  [[<div><p><b>Data Analytics Associate Intern â€“...    No  \n",
       "2  [[<div><p><b>What is the opportunity?</b><br/>...   Yes  \n",
       "3  [[<div><p><b>What is the opportunity?</b><br/>...   Yes  \n",
       "4  [[<div><p><b>What is the opportunity?</b></p><...   Yes  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_df = pd.read_csv('job_postings.csv')\n",
    "old_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_href_from_result(soups):\n",
    "    print('getting job urls')\n",
    "    href = []\n",
    "    for soup in soups:\n",
    "        for div in soup.find_all(name='div', attrs={'class': 'row'}):\n",
    "            for a in div.find_all(name='a', attrs={'data-tn-element': 'jobTitle'}):\n",
    "                href.append('https://ca.indeed.com' + str(a['href']))\n",
    "    return(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting job urls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://ca.indeed.com/company/MDA/jobs/Business-Analyst-Op-Student-1c85976738c57edf?fccid=11f7828cf965b07c&vjs=3'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "href = extract_job_href_from_result(soups)\n",
    "href[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting pages\n",
      "5 pages found\n",
      "10 pages found\n",
      "15 pages found\n",
      "20 pages found\n",
      "25 pages found\n",
      "30 pages found\n",
      "35 pages found\n",
      "40 pages found\n",
      "45 pages found\n",
      "50 pages found\n",
      "55 pages found\n",
      "60 pages found\n",
      "65 pages found\n",
      "70 pages found\n",
      "75 pages found\n",
      "80 pages found\n",
      "85 pages found\n",
      "90 pages found\n",
      "95 pages found\n",
      "100 pages found\n",
      "105 pages found\n",
      "110 pages found\n",
      "115 pages found\n",
      "120 pages found\n",
      "125 pages found\n",
      "130 pages found\n",
      "135 pages found\n",
      "140 pages found\n",
      "145 pages found\n",
      "150 pages found\n",
      "155 pages found\n",
      "160 pages found\n",
      "165 pages found\n",
      "170 pages found\n"
     ]
    }
   ],
   "source": [
    "full_pages = get_pages(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_description(full_pages):\n",
    "    print('getting job descriptions')\n",
    "    descriptions = []\n",
    "    for page in full_pages:\n",
    "        desc = []\n",
    "        for div in page.find_all(attrs={'class': 'jobsearch-jobDescriptionText'}):\n",
    "            desc.append(div.contents)\n",
    "        descriptions.append(desc)\n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = get_job_description(full_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_duplicates(job_titles, companies, locations, href, old_df, descriptions):\n",
    "    print('removing duplicates')\n",
    "    columns = [\"job_title\", \"company\", \"location\", \"href\", 'description', 'apply']\n",
    "    apply = ['NaN']*len(job_titles)\n",
    "    df = pd.DataFrame(list(zip(job_titles, companies, locations, href, descriptions, apply)), columns=columns)\n",
    "    jobs = len(df['job_title'])\n",
    "    print(f'{jobs} total jobs found')\n",
    "    df = pd.concat([old_df, df])\n",
    "    df = df.drop_duplicates(subset=['job_title', 'company'], keep='first')\n",
    "    jobs = len(df['job_title']) - len(old_df['job_title'])\n",
    "    print(f'{jobs} new jobs found')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = check_for_duplicates(job_titles, companies, locations, href, old_df, descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('job_postings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
